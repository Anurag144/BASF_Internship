### Side learnings
* Basic understanding of Databases (MongoDB, Postgres, Neo4J) in context of CRUD operatopns and Aggregation queries.
* Basic understanding of Docker commands and docker compose. [![link](https://stackify.com/docker-tutorial/)]
* Working with Python packages(database clients, networkx ans other basic ones) [![link](https://networkx.org/)]
* Understanding of Data Integration basic concepts (some solutions in general)
* Understanding and development of REST API

### Main objective
* Understanding Aurum paper and work contributed by BASF [![link](https://github.com/mitdbg/aurum-datadiscovery/blob/master/knowledgerepr/fieldnetwork.py)]
* Extending Python Script to get and store similarity scores to Neo4J (currently missing) [![link](https://github.com/mitdbg/aurum-datadiscovery/blob/master/knowledgerepr/fieldnetwork.py)]
* Developing script to add additional edge properties to Neo4J Column similarity graph (generated by Aurum) 
* Building an API (only design) to execute pipeline for Data Integration

### Bonus Point Objective
* Running Aurum on DISQ data
* Scheme to improve profiler of Aurum to accomodate column data ontologies
* Development of a wrapper package (Python and R) around Aurum.

### Minimum expected result
* Understanding Data Integration and Data discovery and some published litrature on this topic.
* Understanding Aurum network building scripts and debugging them.
* Developing scheme for API (only design) to execute pipeline for Data Integration projects
